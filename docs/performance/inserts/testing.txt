===========================
Performance Testing Inserts
===========================

Every setup is different. The best way to tune your particular setup is to do
performance testing.

The easiest way to do this is to use the `cr8`_ tool.

First of all, create a table specifically for performance testing:

.. code-block:: psql

    cr> CREATE TABLE my_table (
    ...   id integer,
    ...   name string
    ... );
    CREATE OK, 1 row affected  (... sec)

This is a simple example. You should create a table that mirrors the sort of
data you plan to use in production.

Next, generate some fake data:

.. code-block:: sh

    sh$ cr8 insert-fake-data \
          --hosts localhost:4200 \
          --table my_table \
          --num-records 1000000

This command will look at your table schema, generate appropriate test data for
the schema, and insert one million test records. You can adjust the number of
records if you wish.

It's important to generate the fake data as a separate step so that our
performance testing isn't also measuring the fake data generation, which in
some situations, might actually end up being the performance bottleneck.

Now, export the the fake data as JSON:

.. code-block:: psql

    cr> COPY my_table TO DIRECTORY "/tmp/crate"
    COPY OK, 1000000 rows affected  (... sec)

We're exporting to the ``/tmp/crate`` directory here, but you can export to any
directory you choose.

Truncate the table:

.. code-block:: psql

    cr> DELETE FROM my_table;
    DELETE OK, 1000000 rows affected  (... sec)

You can then insert the fake data again and measure performance, like so:

.. code-block:: sh

    sh$ cat /tmp/crate/my_table_*.json | cr8 insert-json \
          --hosts localhost:4200 \
          --table my_table \
          --bulk-size 1000 \
          --concurrency 25

.. NOTE::

   The ``--bulk-size`` and ``--concurrency`` values in the above example are
   set to the default values. If you omit these flags, this is the
   configuration that will be used.

The ``insert-json`` command should produce data like this::

    Executing inserts: bulk_size=1000 concurrency=25
    1000 requests [00:35, 27.84 requests/s]
    Runtime (in ms):
        mean:    103.556 ± 3.957
        min/max: 11.587 → 521.434
    Percentile:
        50:   89.764 ± 63.851 (stdev)
        95:   220.739
        99.9: 475.568

From here, you can adjust the configuration values, and compare the results to
understand the performance profile of your setup.

.. NOTE:

   Setting the bulk records size to `1` approximates the performance of single
   inserts.

.. _cr8: https://github.com/mfussenegger/cr8/

