==================
Select Performance
==================

Aggregations and Group By
=========================

It is common to do ``GROUP BY`` queries on tables for analytics purposes. For
example, you might select the ``avg``, ``max``, and ``min`` of some
measurements over a billion records and group them by device ID.

By default, CrateDB processes all matching records. This may require a lot of
processing power, depending on the data set and the size of the CrateDB
cluster.

Similar products sometimes limit the amount of records that are processed for
``GROUP BY`` operations. That means the user might get inaccurate results, but
for analytics this is often an acceptable trade-off.

To emulate this down sampling behavior, users can filter on the ``_docid``
system column using a modulo operation.

Given our previous use case, the query without any filters might look like
this::

   cr> SELECT
      device_id,
      max(value),
      avg(value),
      min(value)
   FROM
      measures
   GROUP BY
      device_id
   ORDER BY
      1 DESC;
   +-----------+------------+-------------------+------------+
   | device_id | max(value) |        avg(value) | min(value) |
   +-----------+------------+-------------------+------------+
   |         4 |      10000 | 5003.748816285036 |          0 |
   |         3 |      10000 | 5005.297395430482 |          0 |
   |         2 |      10000 | 5002.940588080021 |          0 |
   |         1 |      10000 | 5002.216030711031 |          0 |
   +-----------+------------+-------------------+------------+


Now, to speed up this query we can append a ``WHERE _docid % 10 = 0`` filter::

   cr> SELECT
      device_id,
      max(value),
      avg(value),
      min(value)
   FROM
      measures
   WHERE
      _docid % 10 = 0
   GROUP BY
      device_id
   ORDER BY
      1 DESC;

   +-----------+------------+--------------------+------------+
   | device_id | max(value) |         avg(value) | min(value) |
   +-----------+------------+--------------------+------------+
   |         4 |      10000 | 5013.052623224065  |          1 |
   |         3 |      10000 | 4999.1253575025175 |          0 |
   |         2 |      10000 | 5001.400379047543  |          0 |
   |         1 |      10000 | 5035.220951927276  |          0 |
   +-----------+------------+--------------------+------------+

You'll notice that the result changed slightly, but is still fairly close to
the original result.

Note that the ``% 10`` in this example was arbitrary. The higher the number,
the fewer records will match the query and the less accurate the result will
be. This trades accuracy for performance.

.. NOTE::

   The ``_docid`` system column exposes the internal document ID each document
   has within a Lucene segment. The IDs are unique within a segment but not
   across segments or shards. This is good enough for a modulo sampling
   operation.

   Furthermore, the internal ID is basically available free and doesn't have to
   be read from the file system. Making it an ideal candidate for this modulo
   based sampling.
